# DLVS
A novel deep learning based visual servoing  architecture “DLVS” is proposed for control of an unmanned aerial vehicle (UAV) capable of quasi-stationary flight with a camera mounted under the vehicle to track a target consisting of a finite set of stationary points lying in a plane. Current Deep Learning and Reinforcement Learning (RL) based end-to-end servoing approaches rely on training convolutional neural networks using color images with known camera poses to learn the visual features in the environment suitable for servoing tasks. This approach limits the application of the network to known environments where the dataset was collected, moreover such networks cannot be deployed on the low power computers present on board the UAV. The proposed solution employs a time series architecture to learn temporal data from sequential values to output the control ques to the flight controller. The low computational complexity and flexibility of the DLVS architecture ensures real time on board tracking for virtually any target. The algorithm was thoroughly validated in real-life environments and outperformed the current state-of-the-arts in terms of both time efficiency and accuracy.

The model has been trained on a custom dataset that has been self designed and collected. If dataset is required, feel free to contact.
