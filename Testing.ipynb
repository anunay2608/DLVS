{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KerasTensor(type_spec=TensorSpec(shape=(None, 32, 2), dtype=tf.float32, name=None), name='lstm_7/PartitionedCall:1', description=\"created by layer 'lstm_7'\")\n"
     ]
    }
   ],
   "source": [
    "input_layer = tf.keras.layers.Input((32, 3))\n",
    "lstm_1 = tf.keras.layers.LSTM(16, activation=\"tanh\", recurrent_activation='sigmoid', dropout = 0.15, return_sequences = True, return_state = True)(input_layer)\n",
    "lstm_2 = tf.keras.layers.LSTM(64, activation=\"tanh\", recurrent_activation='sigmoid', dropout = 0.15, return_sequences = True, return_state = True)(lstm_1[0])\n",
    "lstm_3 = tf.keras.layers.LSTM(256, activation=\"tanh\", recurrent_activation='sigmoid', dropout = 0.15, return_sequences = True, return_state = True)(lstm_2[0])\n",
    "lstm_4 = tf.keras.layers.LSTM(512, activation=\"tanh\", recurrent_activation='sigmoid', dropout = 0.15, return_sequences = True, return_state = True)(lstm_3[0])\n",
    "lstm_5 = tf.keras.layers.LSTM(256, activation=\"tanh\", recurrent_activation='sigmoid', dropout = 0.15, return_sequences = True, return_state = True)(lstm_4[0])\n",
    "lstm_6 = tf.keras.layers.LSTM(64, activation=\"tanh\", recurrent_activation='sigmoid', dropout = 0.15, return_sequences = True, return_state = True)(lstm_5[0])\n",
    "lstm_7 = tf.keras.layers.LSTM(16, activation=\"tanh\", recurrent_activation='sigmoid', dropout = 0.15, return_sequences = True, return_state = True)(lstm_6[0])\n",
    "lstm_8 = tf.keras.layers.LSTM(2, activation=\"tanh\", recurrent_activation='sigmoid', dropout = 0.15, return_sequences = True, return_state = True)(lstm_7[0])\n",
    "print(lstm_8[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Model(inputs = input_layer, outputs = lstm_8[0], name = \"DLVS_Model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "error_final = []\n",
    "vel_final = []\n",
    "path = \"/home/uas-dtu/Documents/DL_IBVS/Data/\"\n",
    "for a in os.listdir(path):\n",
    "    file = open(path + \"/\" + a, \"r\")\n",
    "    for i in [file.readlines()]:\n",
    "        for j in range(len(i) - 32):\n",
    "#             print(j)\n",
    "            error_data = []\n",
    "            vel_data = []\n",
    "            for k in range(32):\n",
    "                error_data.append([float(i[j + k].split(\",\")[0]), \n",
    "                                   float(i[j + k].split(\",\")[1]),\n",
    "                                   float(i[j + k].split(\",\")[2])])\n",
    "                vel_data.append([float(i[j + k].split(\",\")[3]), \n",
    "                                 float(i[j + k].split(\",\")[4])])\n",
    "            error_final.append(error_data)\n",
    "            vel_final.append(vel_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from tensorflow.keras.utils import Sequence\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import json\n",
    "import random\n",
    "\n",
    "\n",
    "class DataGenerator(Sequence):\n",
    "    def __init__(self, error_final, vel_final,\n",
    "                 batch_size=32,\n",
    "                 shuffle=True):\n",
    "        self.error_final = error_final\n",
    "        self.vel_final = vel_final\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            temp = [i for i in range(len(self.error_final))]\n",
    "            random.shuffle(temp)\n",
    "            #       self.flow_videos = [self.flow_videos[i] for i in temp]\n",
    "            self.error_final = [self.error_final[i] for i in temp]\n",
    "            self.vel_final = [self.vel_final[i] for i in temp]\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.floor(len(self.error_final) / self.batch_size))\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        start_index = index * self.batch_size\n",
    "#         input_1 = []\n",
    "        error_reading = []\n",
    "        vel_reading = []\n",
    "        i = start_index - 1\n",
    "        while len(error_reading) < self.batch_size:\n",
    "            try:\n",
    "                i += 1\n",
    "                error = self.error_final[i%len(self.error_final)]\n",
    "                vel = self.vel_final[i%len(self.vel_final)]\n",
    "                error_reading.append(error)\n",
    "                vel_reading.append(vel)\n",
    "\n",
    "            except Exception as err:\n",
    "                print(err)\n",
    "                continue\n",
    "            \n",
    "        vel_reading = np.array(vel_reading, dtype = np.float32)\n",
    "        error_reading = np.array(error_reading, dtype = np.float32)\n",
    "            \n",
    "        return error_reading, vel_reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = DataGenerator(error_final, vel_final, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Testing ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f571c7cd9b0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_weights(\"./NILU_TRAIN/train_70.tf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.01 0.01]\n",
      "  [0.01 0.01]\n",
      "  [0.01 0.01]\n",
      "  [0.01 0.01]\n",
      "  [0.01 0.01]\n",
      "  [0.01 0.01]\n",
      "  [0.01 0.01]\n",
      "  [0.01 0.01]\n",
      "  [0.01 0.01]\n",
      "  [0.01 0.01]\n",
      "  [0.01 0.01]\n",
      "  [0.04 0.23]\n",
      "  [0.04 0.23]\n",
      "  [0.04 0.23]\n",
      "  [0.04 0.23]\n",
      "  [0.04 0.23]\n",
      "  [0.04 0.23]\n",
      "  [0.04 0.23]\n",
      "  [0.04 0.23]\n",
      "  [0.04 0.23]\n",
      "  [0.09 0.78]\n",
      "  [0.09 0.78]\n",
      "  [0.09 0.78]\n",
      "  [0.09 0.78]\n",
      "  [0.09 0.78]\n",
      "  [0.09 0.78]\n",
      "  [0.09 0.78]\n",
      "  [0.09 0.78]\n",
      "  [0.09 0.78]\n",
      "  [0.09 0.78]\n",
      "  [0.09 0.78]\n",
      "  [0.09 0.78]]]\n",
      "[[[0.04889322 0.7605096 ]\n",
      "  [0.09317811 0.96371317]\n",
      "  [0.1037365  0.994967  ]\n",
      "  [0.11744983 0.9993013 ]\n",
      "  [0.12521642 0.99989784]\n",
      "  [0.12996484 0.9999816 ]\n",
      "  [0.13358606 0.99999386]\n",
      "  [0.13670011 0.999996  ]\n",
      "  [0.1398925  0.99999654]\n",
      "  [0.14356855 0.9999968 ]\n",
      "  [0.14769818 0.9999969 ]\n",
      "  [0.1518993  0.99999684]\n",
      "  [0.15583989 0.999997  ]\n",
      "  [0.15927538 0.999997  ]\n",
      "  [0.1619829  0.9999969 ]\n",
      "  [0.16441086 0.9999969 ]\n",
      "  [0.16662708 0.99999696]\n",
      "  [0.16857767 0.99999696]\n",
      "  [0.17028543 0.9999969 ]\n",
      "  [0.17164165 0.9999969 ]\n",
      "  [0.17264761 0.9999969 ]\n",
      "  [0.17343108 0.9999969 ]\n",
      "  [0.1740775  0.9999969 ]\n",
      "  [0.17463596 0.9999969 ]\n",
      "  [0.17508307 0.9999968 ]\n",
      "  [0.17552295 0.9999969 ]\n",
      "  [0.17594035 0.9999969 ]\n",
      "  [0.17637151 0.9999969 ]\n",
      "  [0.17680152 0.9999969 ]\n",
      "  [0.17728488 0.9999969 ]\n",
      "  [0.17792083 0.9999969 ]\n",
      "  [0.17861396 0.9999969 ]]]\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(train_data.__getitem__(0)[0])\n",
    "print(train_data.__getitem__(0)[1])\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
